## 📊 Multiple Linear Regression

This notebook explores **Multiple Linear Regression**, where multiple independent variables are used to predict a dependent variable. The objective is to understand how different features collectively affect the target variable.

## Key Objectives

- Explore the relationship between multiple independent variables and a dependent variable.
- Build a multiple regression model using **scikit-learn** and **statsmodels**.
- Evaluate model performance and ensure there is no multicollinearity.
- Visualize the relationship between the variables.

## 🔍 Steps Involved

1. **Data Preprocessing**  
   - Handling missing values and outliers.
   - Feature scaling and encoding categorical variables.

2. **Exploratory Data Analysis (EDA)**  
   - Visualizing the data distribution and relationships between variables.

3. **Model Building**  
   - Training the multiple regression model using `scikit-learn`.
   - Checking assumptions (e.g., linearity, homoscedasticity).

4. **Model Evaluation**  
   - Evaluating performance using **R²**, **Adjusted R²**, and residual analysis.

5. **Feature Selection**  
   - Identifying the most significant predictors through statistical tests.

---

### 📦 Libraries Used

- `Pandas`
- `NumPy`
- `Matplotlib`
- `Seaborn`
- `Scikit-learn`
- `Statsmodels`

---

### 📁 Files Included

- `multiple_regression.ipynb`: Jupyter notebook with code for multiple linear regression analysis.
- `data.csv`: Dataset used for building the multiple regression model.

---

## 📈 Expected Outcomes

- Insights into how multiple factors interact and impact the dependent variable.
- A robust model that can be used for prediction with multiple variables.
- Visualizations showing the importance of each feature and the relationship between them.
